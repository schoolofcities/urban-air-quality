{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from calendar import monthrange\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from openaq import OpenAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import FEDERAL_CITIES\n",
    "from constants import FEDERAL_LOCATION_IDS\n",
    "\n",
    "API_KEY = \"be9dde17e764a66a5352413ec62ab925e5b89a58d8fdc4711fc5ad460cdbd29c\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse pollutant data from 2005 to 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:32<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load station-city mapping (preferred stations per city-month)\n",
    "df_station_map = pd.read_csv('../../data/raw/federal/metadata/station_cities.csv')\n",
    "\n",
    "df_station_map = df_station_map.rename(columns={'Unnamed: 0': 'month'})\n",
    "df_station_map['month'] = pd.to_datetime(df_station_map['month'])\n",
    "df_station_map = df_station_map.set_index('month')\n",
    "\n",
    "federal_cities = df_station_map.columns.tolist()\n",
    "\n",
    "# Create full hourly date range from 2005-01-01 to 2025-12-31 23:00\n",
    "date_range = pd.date_range(start=\"2005-01-01\", end=\"2025-12-31 23:00:00\", freq=\"h\")\n",
    "columns = ['pm25', 'no2', 'o3', 'pm25_3h_avg', 'no2_3h_avg', 'o3_3h_avg', 'aqhi_raw', 'aqhi_plus_raw', 'aqhi', 'aqhi_plus']\n",
    "df_empty = pd.DataFrame(index=date_range, columns=columns, dtype=float)\n",
    "\n",
    "output_dir = '../../data/processed/federal/hourly/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for city in tqdm(federal_cities):\n",
    "    filename = f\"{output_dir}{city}.csv\"\n",
    "    df_empty.to_csv(filename)\n",
    "    # print(f\"Initialized {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NO2 → no2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-01-01 00:00:00 St. John's 10102\n",
      "2005-01-01 00:00:00 Halifax 30113\n",
      "2005-01-01 00:00:00 Fredericton 40103\n",
      "2005-01-01 00:00:00 Montréal 50103\n",
      "2005-01-01 00:00:00 Quebec 50308\n",
      "2005-01-01 00:00:00 Sherbrooke 50404\n",
      "2005-01-01 00:00:00 Saguenay 50504\n",
      "2005-01-01 00:00:00 Trois Rivières 50801\n",
      "2005-01-01 00:00:00 Ottawa 60104\n",
      "2005-01-01 00:00:00 Windsor 60204\n",
      "2005-01-01 00:00:00 Toronto 60433\n",
      "2005-01-01 00:00:00 Hamilton 60513\n",
      "2005-01-01 00:00:00 Sudbury 60609\n",
      "2005-01-01 00:00:00 Sault Ste. Marie 60709\n",
      "2005-01-01 00:00:00 Thunder Bay 60809\n",
      "2005-01-01 00:00:00 London 60903\n",
      "2005-01-01 00:00:00 St. Catharines 61302\n",
      "2005-01-01 00:00:00 North Bay 62001\n",
      "2005-01-01 00:00:00 Barrie 65001\n",
      "2005-01-01 00:00:00 Winnipeg 70119\n",
      "2005-01-01 00:00:00 Brandon 70203\n",
      "2005-01-01 00:00:00 Regina 80110\n",
      "2005-01-01 00:00:00 Saskatoon 80211\n",
      "2005-01-01 00:00:00 Prince Albert 80402\n",
      "2005-01-01 00:00:00 Edmonton 90130\n",
      "2005-01-01 00:00:00 Calgary 90222\n",
      "2005-01-01 00:00:00 Lethbridge 90502\n",
      "2005-01-01 00:00:00 Fort Mcmurray 90701\n",
      "2005-01-01 00:00:00 Grande Prairie 92001\n",
      "2005-01-01 00:00:00 Metro Van - Vancouver 100118\n",
      "2005-01-01 00:00:00 Prince George 100202\n",
      "2005-01-01 00:00:00 Victoria 100304\n",
      "2005-01-01 00:00:00 Kamloops 100402\n",
      "2005-01-01 00:00:00 Kelowna 100701\n",
      "2005-01-01 00:00:00 Nanaimo 102102\n",
      "2005-01-01 00:00:00 Whitehorse 119003\n",
      "2005-01-01 00:00:00 Yellowknife 129003\n",
      "2005-02-01 00:00:00 St. John's 10102\n",
      "2005-02-01 00:00:00 Halifax 30113\n",
      "2005-02-01 00:00:00 Fredericton 40103\n",
      "2005-02-01 00:00:00 Montréal 50103\n",
      "2005-02-01 00:00:00 Quebec 50308\n",
      "2005-02-01 00:00:00 Sherbrooke 50404\n",
      "2005-02-01 00:00:00 Saguenay 50504\n",
      "2005-02-01 00:00:00 Trois Rivières 50801\n",
      "2005-02-01 00:00:00 Ottawa 60104\n",
      "2005-02-01 00:00:00 Windsor 60204\n",
      "2005-02-01 00:00:00 Toronto 60433\n",
      "2005-02-01 00:00:00 Hamilton 60513\n",
      "2005-02-01 00:00:00 Sudbury 60609\n",
      "2005-02-01 00:00:00 Sault Ste. Marie 60709\n",
      "2005-02-01 00:00:00 Thunder Bay 60809\n",
      "2005-02-01 00:00:00 London 60903\n",
      "2005-02-01 00:00:00 St. Catharines 61302\n",
      "2005-02-01 00:00:00 North Bay 62001\n",
      "2005-02-01 00:00:00 Barrie 65001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:39<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m df_city\u001b[38;5;241m.\u001b[39mloc[values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m], colname] \u001b[38;5;241m=\u001b[39m values[colname]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Save back to disk\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m \u001b[43mdf_city\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pandas/io/formats/csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pandas/io/formats/csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pandas/io/formats/csvs.py:323\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    320\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[1;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[0;32m--> 323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m libwriters\u001b[38;5;241m.\u001b[39mwrite_csv_rows(\n\u001b[1;32m    325\u001b[0m     data,\n\u001b[1;32m    326\u001b[0m     ix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter,\n\u001b[1;32m    330\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pandas/core/indexes/base.py:1478\u001b[0m, in \u001b[0;36mIndex._get_values_for_csv\u001b[0;34m(self, na_rep, decimal, float_format, date_format, quoting)\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_values_for_csv\u001b[39m(\n\u001b[1;32m   1470\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1471\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1476\u001b[0m     quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1477\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mobject_]:\n\u001b[0;32m-> 1478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pandas/core/indexes/base.py:7795\u001b[0m, in \u001b[0;36mget_values_for_csv\u001b[0;34m(values, date_format, na_rep, quoting, float_format, decimal)\u001b[0m\n\u001b[1;32m   7793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (DatetimeArray, TimedeltaArray)):\n\u001b[1;32m   7794\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 7795\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_native_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7796\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   7797\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pandas/core/arrays/datetimes.py:751\u001b[0m, in \u001b[0;36mDatetimeArray._format_native_types\u001b[0;34m(self, na_rep, date_format, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_dates_only:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;66;03m# Only dates and no timezone: provide a default format\u001b[39;00m\n\u001b[1;32m    749\u001b[0m     date_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 751\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_array_from_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masi8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_creso\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mtslib.pyx:199\u001b[0m, in \u001b[0;36mpandas._libs.tslib.format_array_from_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pollutants = {'NO2': 'no2', 'O3': 'o3', 'PM25': 'pm25'}\n",
    "years = range(2005, 2024)  # 2005–2023\n",
    "\n",
    "for pollutant, colname in pollutants.items():\n",
    "    print(f\"Processing {pollutant} → {colname}\")\n",
    "\n",
    "    for year in tqdm(years):\n",
    "        file_path = f'../../data/raw/federal/{pollutant}/{pollutant}_{year}.csv'\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "\n",
    "        # Read CSV, headers start after 7 lines\n",
    "        df = pd.read_csv(file_path, skiprows=7)\n",
    "\n",
    "        # Extract hourly columns\n",
    "        hour_cols = [c for c in df.columns if c.startswith('H')]\n",
    "\n",
    "        # Melt into long format: one row per hour\n",
    "        melted = df.melt(\n",
    "            id_vars=['Date//Date', 'NAPS ID//Identifiant SNPA'],\n",
    "            value_vars=hour_cols,\n",
    "            var_name='hour',\n",
    "            value_name=colname\n",
    "        )\n",
    "\n",
    "        # Clean datetime\n",
    "        melted['Date//Date'] = pd.to_datetime(melted['Date//Date'])\n",
    "        melted['hour'] = melted['hour'].str.extract(r'H(\\d+)').astype(int)\n",
    "        melted['datetime'] = (\n",
    "            melted['Date//Date']\n",
    "            + pd.to_timedelta(melted['hour'], unit='h')\n",
    "            + pd.Timedelta(hours=1)\n",
    "        )\n",
    "        melted = melted.drop(columns=['hour', 'Date//Date'])\n",
    "\n",
    "        # Filter invalid values\n",
    "        melted[colname] = melted[colname].apply(\n",
    "            lambda x: np.nan if pd.isna(x) or x in [-999, 9999] else x\n",
    "        )\n",
    "\n",
    "        # Group by station ID for fast lookup\n",
    "        station_groups = dict(tuple(melted.groupby('NAPS ID//Identifiant SNPA')))\n",
    "\n",
    "        # Loop through months in this year\n",
    "        year_months = pd.date_range(start=f\"{year}-01-01\", end=f\"{year}-12-31\", freq=\"MS\")\n",
    "        for month in year_months:\n",
    "            if month not in df_station_map.index:\n",
    "                continue\n",
    "\n",
    "            for city in federal_cities:\n",
    "                station_id = df_station_map.loc[month, city]\n",
    "                if pd.isna(station_id):\n",
    "                    continue  # no station for this city this month\n",
    "                \n",
    "                print(month, city, station_id)\n",
    "\n",
    "                station_id = int(station_id)  # normalize ID\n",
    "                if station_id not in station_groups:\n",
    "                    continue  # station not found in file\n",
    "\n",
    "                sub = station_groups[station_id]\n",
    "                mask = sub['datetime'].dt.to_period(\"M\") == month.to_period(\"M\")\n",
    "                values = sub.loc[mask, ['datetime', colname]]\n",
    "                if values.empty:\n",
    "                    continue\n",
    "\n",
    "                # Load this city's CSV (datetime index restored automatically)\n",
    "                city_file = f\"{output_dir}{city}.csv\"\n",
    "                df_city = pd.read_csv(city_file, index_col=0, parse_dates=True)\n",
    "\n",
    "                # Assign new values\n",
    "                df_city.loc[values['datetime'], colname] = values[colname].values\n",
    "\n",
    "                # Save back to disk\n",
    "                df_city.to_csv(city_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use OpenAQ to query for pollutant data over 2024 and 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:06<00:00,  6.24it/s]\n"
     ]
    }
   ],
   "source": [
    "client = OpenAQ(api_key=API_KEY)\n",
    "\n",
    "sensor_records = []\n",
    "\n",
    "for city, location_id in tqdm(FEDERAL_LOCATION_IDS.items()):\n",
    "    if location_id is None:\n",
    "        sensor_records.append([city, '', '', '', '', ''])\n",
    "        continue\n",
    "\n",
    "    sensors = client.locations.sensors(location_id).results\n",
    "\n",
    "    for sensor in sensors:\n",
    "        if sensor.parameter['name'] in ['pm25', 'o3', 'no2']:\n",
    "            sensor_records.append([\n",
    "                city, \n",
    "                location_id, \n",
    "                sensor.id,\n",
    "                sensor.parameter['name'],\n",
    "                sensor.datetime_first['local'],\n",
    "                sensor.datetime_last['local'],\n",
    "            ])\n",
    "\n",
    "df = pd.DataFrame.from_records(sensor_records, columns=['city', 'location_id', 'sensor_id', 'pollutant', 'date_first', 'date_last'])\n",
    "df.to_csv('../../data/raw/federal/metadata/sensors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St. John's\n"
     ]
    }
   ],
   "source": [
    "for city, location_id, sensor_id, pollutant, date_start, date_end in sensor_records:\n",
    "    if not sensor_id:\n",
    "        continue\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAQ(api_key=API_KEY)\n",
    "response = client.measurements.list(\n",
    "    sensors_id=25148, \n",
    "    limit=1000,\n",
    "    page=13,\n",
    "    datetime_from='2024-01-01',  # need to do 2024-2025, then 2025-2026 \n",
    "    datetime_to='2026-01-01',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1346572/3699858157.py:14: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  end_date = datetime.utcnow().isoformat() + \"Z\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Measurements.list() got an unexpected keyword argument 'location_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_results\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Fetch data\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_all_measurements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n\u001b[1;32m     43\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m, in \u001b[0;36mfetch_all_measurements\u001b[0;34m(location_id, start_date, end_date, limit)\u001b[0m\n\u001b[1;32m     19\u001b[0m all_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasurements\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Corrected parameter name\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     results \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n",
      "\u001b[0;31mTypeError\u001b[0m: Measurements.list() got an unexpected keyword argument 'location_id'"
     ]
    }
   ],
   "source": [
    "from openaq import OpenAQ\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize client with API key\n",
    "API_KEY = \"0d33157cc065493f21b56c03c868fead2ba85358f4c6d1cffa7e1e91dd560f50\"\n",
    "client = OpenAQ(api_key=API_KEY)\n",
    "\n",
    "# Station ID\n",
    "location_id = 774\n",
    "\n",
    "# Date range\n",
    "start_date = '2024-01-01T00:00:00Z'\n",
    "end_date = datetime.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "# Function to fetch all measurements with pagination\n",
    "def fetch_all_measurements(location_id, start_date, end_date, limit=1000):\n",
    "    page = 1\n",
    "    all_results = []\n",
    "\n",
    "    while True:\n",
    "        response = client.measurements.list(\n",
    "            location_id=location_id,  # Corrected parameter name\n",
    "            date_from=start_date,\n",
    "            date_to=end_date,\n",
    "            limit=limit,\n",
    "            page=page\n",
    "        )\n",
    "        results = response['results']\n",
    "        if not results:\n",
    "            break\n",
    "        \n",
    "        all_results.extend(results)\n",
    "        print(f\"Fetched page {page} with {len(results)} records\")\n",
    "        page += 1\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# Fetch data\n",
    "data = fetch_all_measurements(location_id, start_date, end_date)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optional: show first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"station_774_measurements.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
