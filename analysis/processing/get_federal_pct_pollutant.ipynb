{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "from calendar import monthrange\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from openaq import OpenAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import FEDERAL_LOCATION_IDS\n",
    "\n",
    "FEDERAL_CITIES = list(FEDERAL_LOCATION_IDS.keys())\n",
    "years = list(range(2005, 2026))\n",
    "\n",
    "COVERAGE_DIR = \"../../data/processed/federal/metadata/coverage/yearly\"\n",
    "COVERAGE_THRESHOLD = 50  # Only include years with >=50% coverage\n",
    "\n",
    "OUTPUT_DIR = \"../../data/results/federal_pct_pollutant\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_aqhi(pm25_3h, no2_3h, o3_3h):\n",
    "    \"\"\"Compute federal AQHI from 3-hour averages.\"\"\"\n",
    "    aqhi = (\n",
    "        1000 * (\n",
    "            (np.exp(0.000871 * no2_3h) - 1) +\n",
    "            (np.exp(0.000537 * o3_3h) - 1) +\n",
    "            (np.exp(0.000487 * pm25_3h) - 1)\n",
    "        )\n",
    "    ) / 10.4\n",
    "    return aqhi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pct_contrib(df):\n",
    "    \"\"\"\n",
    "    Given a DataFrame with pm25_3h_avg, no2_3h_avg, o3_3h_avg, and aqhi_raw,\n",
    "    compute hourly percentage contribution of each pollutant to AQHI.\n",
    "    Returns df with new columns: pct_pm25, pct_no2, pct_o3.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Compute pollutant-specific AQHI\n",
    "    aqhi_pm25 = compute_aqhi(df['pm25_3h_avg'], 0, 0)\n",
    "    aqhi_no2 = compute_aqhi(0, df['no2_3h_avg'], 0)\n",
    "    aqhi_o3 = compute_aqhi(0, 0, df['o3_3h_avg'])\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    mask = df['aqhi_raw'] > 0\n",
    "    \n",
    "    df['pct_pm25'] = np.nan\n",
    "    df['pct_no2'] = np.nan\n",
    "    df['pct_o3'] = np.nan\n",
    "    \n",
    "    df.loc[mask, 'pct_pm25'] = aqhi_pm25[mask] / df.loc[mask, 'aqhi_raw'] * 100\n",
    "    df.loc[mask, 'pct_no2'] = aqhi_no2[mask] / df.loc[mask, 'aqhi_raw'] * 100\n",
    "    df.loc[mask, 'pct_o3'] = aqhi_o3[mask] / df.loc[mask, 'aqhi_raw'] * 100\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_yearly_pct_contrib(case='all'):\n",
    "    \"\"\"\n",
    "    Compute average yearly percent contribution for each pollutant per city.\n",
    "    \n",
    "    Parameters:\n",
    "    - case: 'all' -> all AQHI, 'high' -> only hours with aqhi_raw >= 7\n",
    "    \n",
    "    Returns:\n",
    "    - dict: {pollutant: DataFrame(cities x years)}\n",
    "    \"\"\"\n",
    "    pollutants = ['pm25', 'no2', 'o3']\n",
    "    results = {poll: pd.DataFrame(np.nan, index=FEDERAL_CITIES, columns=years) for poll in pollutants}\n",
    "\n",
    "    for city in tqdm(FEDERAL_CITIES):\n",
    "        city_path = f\"../../data/processed/federal/hourly/{city}.csv\"\n",
    "        coverage_path = f\"{COVERAGE_DIR}/{city}.csv\"\n",
    "        \n",
    "        if not os.path.exists(city_path) or not os.path.exists(coverage_path):\n",
    "            continue\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_csv(city_path, index_col=0, parse_dates=True)\n",
    "        if df.empty or 'aqhi_raw' not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        # Load coverage metadata\n",
    "        try:\n",
    "            df_cov = pd.read_csv(coverage_path, index_col=0)\n",
    "            valid_years = df_cov.index[df_cov['aqhi'] >= COVERAGE_THRESHOLD].astype(int).tolist()\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # Compute hourly percent contributions\n",
    "        df = compute_pct_contrib(df)\n",
    "        \n",
    "        if case == 'high':\n",
    "            df = df[df['aqhi_raw'] >= 7]\n",
    "        elif case == 'medium':\n",
    "            df = df[df['aqhi_raw'] >= 4]\n",
    "        \n",
    "        # Compute yearly averages\n",
    "        for year in years:\n",
    "            if year not in valid_years:\n",
    "                continue\n",
    "            mask = df.index.year == year\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            for poll in pollutants:\n",
    "                results[poll].loc[city, year] = df.loc[mask, f'pct_{poll}'].mean()\n",
    "    \n",
    "    for poll in pollutants:\n",
    "        results[poll] = results[poll].round(2)\n",
    "        results[poll] = results[poll].rename(index={'Metro Van - Vancouver': 'Vancouver'})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:12<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ../../data/results/federal_pct_pollutant/pm25_pct.csv\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/no2_pct.csv\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/o3_pct.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:09<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ../../data/results/federal_pct_pollutant/pm25_pct_high.csv\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/no2_pct_high.csv\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/o3_pct_high.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:11<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ../../data/results/federal_pct_pollutant/pm25_pct_medium.csv\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/no2_pct_medium.csv\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/o3_pct_medium.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cases: all AQHI vs high AQHI (>=7)\n",
    "cases = {'all': '', 'high': 'high', 'medium': 'medium'}\n",
    "\n",
    "for case_name, suffix in cases.items():\n",
    "    yearly_results = compute_yearly_pct_contrib(case=case_name)\n",
    "    \n",
    "    for poll, df in yearly_results.items():\n",
    "        path_suffix = '' if case_name == 'all' else f'_{case_name}'\n",
    "        csv_path = os.path.join(OUTPUT_DIR, f\"{poll}_pct{path_suffix}.csv\")\n",
    "        df.to_csv(csv_path)\n",
    "        print(f\"✅ Saved: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ../../data/results/federal_pct_pollutant/no2_pct_medium.json\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/pm25_pct_medium.json\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/o3_pct_high.json\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/o3_pct.json\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/pm25_pct.json\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/o3_pct_medium.json\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/no2_pct_high.json\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/pm25_pct_high.json\n",
      "✅ Saved: ../../data/results/federal_pct_pollutant/no2_pct.json\n"
     ]
    }
   ],
   "source": [
    "for csv_file in os.listdir(OUTPUT_DIR):\n",
    "    if not csv_file.endswith(\".csv\"):\n",
    "        continue\n",
    "    # if 'pm25' not in csv_file:\n",
    "    #     continue\n",
    "\n",
    "    csv_path = os.path.join(OUTPUT_DIR, csv_file)\n",
    "    json_path = os.path.join(OUTPUT_DIR, csv_file.replace(\".csv\", \".json\"))\n",
    "\n",
    "    # Read CSV with first column as index (assumed to be city)\n",
    "    df = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "    # Replace NaN and NaT with None (JSON null)\n",
    "    df = df.replace({np.nan: None})\n",
    "\n",
    "    # Convert to dict of dicts — {city: {col1: val1, col2: val2, ...}}\n",
    "    json_dict = df.to_dict(orient=\"index\")\n",
    "\n",
    "    # Write to JSON\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_dict, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"✅ Saved: {json_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
