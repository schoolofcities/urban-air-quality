{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "from calendar import monthrange\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from openaq import OpenAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import FEDERAL_LOCATION_IDS\n",
    "\n",
    "FEDERAL_CITIES = list(FEDERAL_LOCATION_IDS.keys())\n",
    "years = list(range(2005, 2026))\n",
    "\n",
    "COVERAGE_DIR = \"../../data/processed/federal/metadata/coverage/yearly\"\n",
    "COVERAGE_THRESHOLD = 50  # percent\n",
    "\n",
    "# Define only the ranges we need for the CSV outputs\n",
    "categories_to_save = {\n",
    "    \"aqhi\": {\n",
    "        \"7plus\": (7, np.inf),\n",
    "        \"11plus\": (11, np.inf),\n",
    "    },\n",
    "    \"aqhi_plus\": {\n",
    "        \"7plus\": (7, np.inf),\n",
    "        \"11plus\": (11, np.inf),\n",
    "    },\n",
    "    \"pm25\": {\n",
    "        \"55_5plus\": (55.5, np.inf),\n",
    "        \"250_5plus\": (250.5, np.inf),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_days(case, col, categories):\n",
    "    \"\"\"\n",
    "    Compute number of days per city per year falling within each category.\n",
    "    Only include years where coverage >= 50% for the pollutant/metric.\n",
    "    Returns a dict of {category_name: DataFrame(cities x years)}.\n",
    "    \"\"\"\n",
    "    results = {cat: pd.DataFrame(0, index=FEDERAL_CITIES, columns=years) for cat in categories}\n",
    "\n",
    "    print(f\"Processing {case}\")\n",
    "    for city in tqdm(FEDERAL_CITIES):\n",
    "        dir_end = case\n",
    "        if case == \"aqhi_plus\":\n",
    "            dir_end = \"aqhi-plus\"\n",
    "\n",
    "        daily_path = f\"../../data/processed/federal/daily-{dir_end}/{city}.csv\"\n",
    "        coverage_path = f\"{COVERAGE_DIR}/{city}.csv\"\n",
    "\n",
    "        # Skip if either file missing\n",
    "        if not os.path.exists(daily_path) or not os.path.exists(coverage_path):\n",
    "            continue\n",
    "\n",
    "        # Load daily data\n",
    "        df_daily = pd.read_csv(daily_path, index_col=0, parse_dates=True)\n",
    "        if col not in df_daily.columns:\n",
    "            continue\n",
    "        series = pd.to_numeric(df_daily[col], errors=\"coerce\").dropna()\n",
    "        if series.empty:\n",
    "            continue\n",
    "\n",
    "        # Load coverage metadata\n",
    "        try:\n",
    "            df_cov = pd.read_csv(coverage_path, index_col=0)\n",
    "            # Identify valid years with >= 50% coverage for this metric\n",
    "            valid_years = df_cov.index[df_cov[case] >= COVERAGE_THRESHOLD].astype(int).tolist()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping {city} (coverage load error: {e})\")\n",
    "            continue\n",
    "\n",
    "        for cat_name, (low, high) in categories.items():\n",
    "            mask = (series >= low) & (series <= high if np.isfinite(high) else True)\n",
    "            filtered = series[mask]\n",
    "            if filtered.empty:\n",
    "                continue\n",
    "\n",
    "            yearly_counts = filtered.groupby(filtered.index.year).size()\n",
    "\n",
    "            # Only record counts for valid coverage years\n",
    "            for year, count in yearly_counts.items():\n",
    "                results[cat_name].loc[city, year] = count\n",
    "\n",
    "            for year in years:\n",
    "                if year not in valid_years:\n",
    "                    results[cat_name].loc[city, year] = np.nan\n",
    "\n",
    "    for cat in results:\n",
    "        results[cat] = results[cat].rename(index={'Metro Van - Vancouver': 'Vancouver'})\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing aqhi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 77.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing aqhi_plus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 73.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pm25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 79.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished generating all 6 CSV files!\n"
     ]
    }
   ],
   "source": [
    "# Output directory\n",
    "out_dir = \"../../data/results/federal_num_days\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# ---- AQHI ----\n",
    "aqhi_results = compute_num_days(\"aqhi\", \"max_aqhi\", categories_to_save[\"aqhi\"])\n",
    "for cat, df in aqhi_results.items():\n",
    "    df.to_csv(f\"{out_dir}/aqhi_{cat}.csv\")\n",
    "\n",
    "# ---- AQHI+ ----\n",
    "aqhi_plus_results = compute_num_days(\"aqhi_plus\", \"max_aqhi_plus\", categories_to_save[\"aqhi_plus\"])\n",
    "for cat, df in aqhi_plus_results.items():\n",
    "    df.to_csv(f\"{out_dir}/aqhi_plus_{cat}.csv\")\n",
    "\n",
    "# ---- PM2.5 ----\n",
    "pm25_results = compute_num_days(\"pm25\", \"max_pm25\", categories_to_save[\"pm25\"])\n",
    "for cat, df in pm25_results.items():\n",
    "    df.to_csv(f\"{out_dir}/pm25_{cat}.csv\")\n",
    "\n",
    "print(\"✅ Finished generating all 6 CSV files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ../../data/results/federal_num_days/pm25_55_5plus.json\n",
      "✅ Saved: ../../data/results/federal_num_days/pm25_250_5plus.json\n",
      "✅ Saved: ../../data/results/federal_num_days/aqhi_7plus.json\n",
      "✅ Saved: ../../data/results/federal_num_days/aqhi_plus_7plus.json\n",
      "✅ Saved: ../../data/results/federal_num_days/aqhi_plus_11plus.json\n",
      "✅ Saved: ../../data/results/federal_num_days/aqhi_11plus.json\n",
      "🎉 All summary JSONs generated successfully.\n"
     ]
    }
   ],
   "source": [
    "results_dir = \"../../data/results/federal_num_days\"\n",
    "output_dir = results_dir\n",
    "\n",
    "# Loop through each CSV file\n",
    "for csv_file in os.listdir(results_dir):\n",
    "    if not csv_file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    csv_path = os.path.join(results_dir, csv_file)\n",
    "    json_path = os.path.join(output_dir, csv_file.replace(\".csv\", \".json\"))\n",
    "\n",
    "    # Read CSV with city as index (first column)\n",
    "    df = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "    # Replace NaN and NaT with None (JSON null)\n",
    "    df = df.replace({np.nan: None})\n",
    "\n",
    "    # Convert to dict of dicts — {city: {col1: val1, col2: val2, ...}}\n",
    "    json_dict = df.to_dict(orient=\"index\")\n",
    "\n",
    "    # Write to JSON\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_dict, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"✅ Saved: {json_path}\")\n",
    "\n",
    "print(\"🎉 All summary JSONs generated successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
